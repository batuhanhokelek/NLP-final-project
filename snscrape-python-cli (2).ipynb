{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snscrape in ./opt/anaconda3/lib/python3.9/site-packages (0.4.3.20220106)\n",
      "Requirement already satisfied: beautifulsoup4 in ./opt/anaconda3/lib/python3.9/site-packages (from snscrape) (4.10.0)\n",
      "Requirement already satisfied: requests[socks] in ./opt/anaconda3/lib/python3.9/site-packages (from snscrape) (2.26.0)\n",
      "Requirement already satisfied: lxml in ./opt/anaconda3/lib/python3.9/site-packages (from snscrape) (4.6.3)\n",
      "Requirement already satisfied: filelock in ./opt/anaconda3/lib/python3.9/site-packages (from snscrape) (3.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->snscrape) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests[socks]->snscrape) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests[socks]->snscrape) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests[socks]->snscrape) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from requests[socks]->snscrape) (2.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in ./opt/anaconda3/lib/python3.9/site-packages (from requests[socks]->snscrape) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query by Keyword Search\n",
    "The code below will scrape tweets between May 1st, 2021 and May 1st, 2022, by a text search then provide a CSV file with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"mülteci\",\"mülteciyi\",\"mülteciye\",\"mültecide\",\"mülteciden\",\n",
    "            \"mülteciler\",\"mültecileri\",\"mültecilere\",\"mültecilerde\", \"mültecilerden\",\n",
    "            \"multeci\", \"multeciyi\",\"multeciye\",\"multecide\",\"multeciden\",\n",
    "            \"multeciler\", \"multecileri\", \"multecilere\", \"multecilerde\",\"multecilerden\",\n",
    "            \n",
    "            \"mültecinin\",\"mültecimiz\",\n",
    "            \"mültecilerin\",\"mültecilerimiz\",\n",
    "            \"multecinin\",\"multecimiz\",\n",
    "            \"multecilerin\",\"multecilerimiz\",\n",
    "            \n",
    "            \n",
    "            \"göçmen\", \"göçmeni\", \"göçmene\",\"göçmende\", \"göçmenden\",\n",
    "            \"gocmen\", \"gocmeni\", \"gocmene\", \"gocmende\", \"gocmenden\",\n",
    "            \"göçmenler\", \"göçmenleri\",\"göçmenlere\",\"göçmenlerde\",\"göçmenlerden\",\n",
    "            \"gocmenler\", \"gocmenleri\", \"gocmenlere\", \"gocmenlerde\",\"gocmenlerden\",\n",
    "            \n",
    "            \"göçmenin\",\"göçmenimiz\",\n",
    "            \"gocmenin\",\"gocmenimiz\",\n",
    "            \"gocmenlerin\",\"gocmenimiz\",\n",
    "            \"göçmenlerin\",\"göçmenlerimiz\",\n",
    "            \n",
    "            \n",
    "            \"sığınmacı\",\"sığınmacıyı\",\"sığınmacıya\",\"sığınmacıda\",\"sığınmacıdan\",\n",
    "            \"sığınmacılar\", \"sığınmacıları\", \"sığınmacıya\", \"sığınmacıda\", \"sığınmacıdan\",\n",
    "            \"siginmaci\", \"siginmaciyi\",\"siginmaciya\",\"siginmacida\",\"siginmacidan\",\n",
    "            \"siginmacilar\", \"siginmacilari\",\"siginmacilara\",\"siginmacilarda\",\"siginmacilardan\",\n",
    "            \n",
    "            \"sığınmacının\",\"sığınmacımız\",\n",
    "            \"siginmacinin\",\"siginmacimiz\",\n",
    "            \"sığınmacılarının\",\"sığınmacılarımız\",\n",
    "            \"siginmacilarinin\",\"siginmacilarimiz\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting variables to be used in format string command below\n",
    "tweet_count = 700 #max for each keyword.\n",
    "since_date = \"2021-05-01\"\n",
    "until_date = \"2022-05-01\"\n",
    "\n",
    "# Using OS library to call CLI commands in Python\n",
    "for keyword in keywords:\n",
    "    os.system('snscrape --jsonl --max-results {} --since {} twitter-search \"{} until:{}\">> text-query-tweets.json'.format(tweet_count, since_date, keyword, until_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/Users/isiktopcu/Desktop/refugee_raw_sns.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reads the json generated from the CLI command above and creates a pandas dataframe\n",
    "tweets_df2 = pd.read_json(\"./refugee_raw_sns.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many tweets? \n",
    "len(tweets_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframe into a CSV\n",
    "tweets_df2.to_csv('text-query-tweets.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt = pd.read_csv('text-query-tweets.csv')\n",
    "dt.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#how many tweets for each keyword? \n",
    "for keyword in keywords: \n",
    "    print(str(keyword) + \" : \"+ str(len(dt[dt[\"content\"].str.equals(keyword)==True])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
